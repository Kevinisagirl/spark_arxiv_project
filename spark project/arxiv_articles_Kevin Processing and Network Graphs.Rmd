---
title: "arxiv_article_data"
author: "Kevin Hunt"
date: "May 13, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggthemes)
library(networkD3)
library(knitr)
library(kableExtra)
```

```{r}
articledata <- do.call(rbind,strsplit(readLines("removed_newlines_all_article_data.txt"), "@@@",fixed=T))
str(as.data.frame(articledata, stringsAsFactors = FALSE))

articles_processed <- 
  setNames(
    as.data.frame(lapply(1:ncol(articledata), function (i) {
      type.convert(articledata[,i], as.is = TRUE)
    }), stringsAsFactors = FALSE),
    c("arxiv-id", "title", "Authors", "Affiliations", "Journal Reference", "Comments", "Primary Category", "Categories", "Abstract")
  )

articles_processed$`arxiv-id` <- gsub("arxiv-id: ", "", articles_processed$`arxiv-id`)
articles_processed$title <- gsub("Title:  ", "", articles_processed$title)
articles_processed$Authors <- gsub("Authors:  ", "", articles_processed$Authors)
articles_processed$Affiliations <- gsub("Affiliations: ", "", articles_processed$Affiliations)
articles_processed$`Journal Reference` <- gsub("Journal reference: ", "", articles_processed$`Journal Reference`)
articles_processed$Comments <- gsub("Comments: ", "", articles_processed$Comments)
articles_processed$`Primary Category` <- gsub("Primary Category: ", "", articles_processed$`Primary Category`)
articles_processed$Categories <- gsub("All Categories: ", "", articles_processed$Categories)
articles_processed$Abstract <- gsub("Abstract: ", "", articles_processed$Abstract)

head(articles_processed) %>%
  kable("html") %>%
  kable_styling()
```

## Update Categories

Load in all the category tags
```{r}
physics <- do.call(rbind,strsplit(readLines("categories/physics.txt"), ": ",fixed=T))
physics <- as.data.frame(physics)
physics <- setNames(physics, c("catcode", "category"))

cs <- do.call(rbind,strsplit(readLines("categories/computer\ science.txt"), ": ",fixed=T))
cs <- as.data.frame(cs)
cs <- setNames(cs, c("catcode", "category"))

mathematics <- do.call(rbind,strsplit(readLines("categories/mathematics.txt"), ": ",fixed=T))
mathematics <- as.data.frame(mathematics)
mathematics <- setNames(mathematics, c("catcode", "category"))

quantBio <- do.call(rbind,strsplit(readLines("categories/quantitative\ biology.txt"), ": ",fixed=T))
quantBio <- as.data.frame(quantBio)
quantBio <- setNames(quantBio, c("catcode", "category"))

quantFin <- do.call(rbind,strsplit(readLines("categories/quantitative\ finance.txt"), ": ",fixed=T))
quantFin <- as.data.frame(quantFin)
quantFin <- setNames(quantFin, c("catcode", "category"))

statistics <- do.call(rbind,strsplit(readLines("categories/statistics.txt"), ": ",fixed=T))
statistics <- as.data.frame(statistics)
statistics <- setNames(statistics, c("catcode", "category"))
```

Combine all the tags into one df with the major category
```{r}
cat_tags <- physics
cat_tags$category <- "Physics"
adj.cat <- cs
adj.cat$category <- "Computer Science"
cat_tags <- rbind(cat_tags, adj.cat)
adj.cat <- mathematics
adj.cat$category <- "Mathematics"
cat_tags <- rbind(cat_tags, adj.cat)
adj.cat <- quantBio
adj.cat$category <- "Quantitative Biology"
cat_tags <- rbind(cat_tags, adj.cat)
adj.cat <- quantFin
adj.cat$category <- "Quantitative Finance"
cat_tags <- rbind(cat_tags, adj.cat)
adj.cat <- statistics
adj.cat$category <- "Statistics"
cat_tags <- rbind(cat_tags, adj.cat)

# manually add some tags
cat_tags <- rbind(cat_tags, data.frame(catcode="econ.EM", category="Econometrics"))
cat_tags <- rbind(cat_tags, data.frame(catcode="eess.AS", category="Electrical Engineering\nand Systems Science"))
cat_tags <- rbind(cat_tags, data.frame(catcode="eess.IV", category="Electrical Engineering\nand Systems Science"))
cat_tags <- rbind(cat_tags, data.frame(catcode="eess.SP", category="Electrical Engineering\nand Systems Science"))

# add categories that we have no articles for (I did not include all catcodes for these)
cat_tags <- rbind(cat_tags, data.frame(catcode="cond-mat.dis-nn", category="Condensed Matter"))
cat_tags <- rbind(cat_tags, data.frame(catcode="nlin.AO", category="Nonlinear Sciences"))

# update astro-ph. to astrophysics
cat_tags[grep("astro-ph.", cat_tags$catcode), "category"] <- "Astrophysics"

cat_tags$category <- factor(cat_tags$category)
unique(cat_tags$category)
```

Using major categories

```{r}
articles_major_cats <- merge(articles_processed, cat_tags, by.x = "Primary Category", by.y = "catcode", all.x = TRUE)
articles_major_cats$category <- factor(articles_major_cats$category)

countsofcat <- articles_major_cats %>%
  group_by(category) %>%
  summarize(count=n())
my_theme <- theme_tufte()
ggplot(countsofcat, aes(x=reorder(category,-count), y=count)) + geom_bar(fill='lightgreen', stat="identity") + coord_flip() + xlab(NULL) + my_theme  + ylab("Article Counts")
```

### Use This!!
```{r}
tmp.hold <- data.frame(article_id=character(),
                       author=character())
for(i in 1:nrow(articles_major_cats)){
  authors <- articles_major_cats[i, "Authors"]
  authorlist <- strsplit(authors, split=", ")[[1]]
  combos <- cbind(articles_major_cats[i,"arxiv-id"], authorlist)
  tmp.hold <- rbind(as.matrix(tmp.hold), as.matrix(combos))
}

#remember to remove "." and ":"
tmp.hold <- data.frame(tmp.hold)
author.key <- tmp.hold[-which(tmp.hold$author %in% c(":",".")),]

# convert to source targets
links <- data.frame(Source=character(),
                       Target=character())
for(i in 1:nrow(author.key)){
  current_id = as.character(author.key[i,"article_id"])
  current_author = as.character(author.key[i,'author'])
  authors.articles = as.character(author.key[which(author.key$author == current_author), "article_id"])
  combos <- cbind(current_id, authors.articles)
  links <- rbind(as.matrix(links), as.matrix(combos))
}

links <- data.frame(t(apply(links,1,sort)))
links <- unique(links)
links <- links[which(links$X1 != links$X2),]
```


```{r}
net <- simpleNetwork(links, height=400, width=400, zoom = TRUE)
saveNetwork(net, "all_article_links.html", selfcontained = TRUE)
```

This works much better and looks cooler!

let's see a histogram of how many connections an article has
```{r}
sources <- as.character(links$X1)
targets <- as.character(links$X2)
together <- c(sources, targets)
dat2 <- data.frame(fac = factor(together))
hist(table(dat2), xlab = "Number of Connections", main = "The Number of Connections an Article Has with Other Articles\nBased on Shared Authors", breaks=c(seq(0,10,by=1), 65), col = "lightgreen")
hist(table(dat2), xlab = "Number of Connections", main = "The Number of Connections an Article Has with Other Articles\nBased on Shared Authors", breaks=c(seq(0,10,by=1), 65), xlim=c(0,10), col = "lightgreen")
```

Looks like half of these are a single connection between two nodes. Let's filter for those
```{r}
count_list <- data.frame(table(unlist(together)))
only_one_occurence <- as.character(count_list[which(count_list$Freq == 1), "Var1"])

dense_links <- links[-which(links$X1 %in% only_one_occurence & links$X2 %in% only_one_occurence),]
```

## forceNetwork
```{r}
flinks <- links
flinks$value <- 1
flinks$source <- as.numeric(flinks$X1)
flinks$target <- as.numeric(flinks$X2)

fnodes <- articles_major_cats[,which(names(articles_major_cats) %in% c("arxiv-id", "category"))]
fnodes$size <- articles_major_cats[match(articles_major_cats$`arxiv-id`, fnodes$`arxiv-id`),"Authors"]
fnodes$size <- lengths(gregexpr(", ", fnodes$size)) +1

fnet <- forceNetwork(Links=flinks, Nodes=fnodes, Source="source", Target="target", Value="value", NodeID="arxiv-id", Nodesize = "size", Group="category", opacity=0.8, zoom=TRUE, linkDistance=25, charge=0)
saveNetwork(fnet, "force_article_links.html", selfcontained = TRUE)
```


```{r}
dflinks <- dense_links
# have to adjust nodes to only contain nodes to plot
all.dense.articles <- unique(c(as.character(dflinks$X1), as.character(dflinks$X2)))
dfnodes <- fnodes[which(fnodes$`arxiv-id` %in% all.dense.articles),]
dfnodes$category <- relevel(dfnodes$category, "Physics")
dfnodes <- dfnodes[order(dfnodes$category),]
row.names(dfnodes) <- NULL
dfnodes$index <- rownames(dfnodes)

dflinks$value <- 1
dflinks$source <- as.numeric(dfnodes[match(dflinks$X1, dfnodes$`arxiv-id`), "index"])-1
dflinks$target <- as.numeric(dfnodes[match(dflinks$X2, dfnodes$`arxiv-id`), "index"])-1
dflinks <- dflinks[order(dflinks$source),]

dfnet <- forceNetwork(Links=dflinks, Nodes=dfnodes, Source="source", Target="target", Value="value", NodeID="arxiv-id", Nodesize = "size", Group="category", opacity=0.8, legend=TRUE, zoom=TRUE, linkDistance=25, charge=-5)
saveNetwork(dfnet, "dense_force_article_links.html", selfcontained = TRUE)
```

```{r}
hist(fnodes$size, labels=TRUE, ylim=c(0,11000), col="lightgreen")
hist(fnodes$size, breaks=c(seq(1,20,by=1),439), xlim=c(0.6,20), ylim=c(0,5000),labels=TRUE, freq=TRUE, col="lightgreen")
```

## Work that was done, but not utilized - commented out because hefty and slows down session
Trim the data down so only authors that appear on more than 1 journal are used as sources
Here we will get a list of the authors that appear on more than 1 article
```{r}
# all_authors <- vector('character')
# 
# for(i in 1:nrow(articles_major_cats)){
#   authors <- articles_major_cats[i, "Authors"]
#   authorlist <- strsplit(authors, split=", ")[[1]]
#   if(length(authorlist) > 1){
#     all_authors <- c(all_authors, authorlist)
#   }
# }
# 
# # results in 35480 unique authors that have published with others
# 
# 
# # 5107 unique authors that are present on more than 1 article
```

```{r}
# really_all_authors <- vector('character')
# 
# for(i in 1:nrow(articles_major_cats)){
#   authors <- articles_major_cats[i, "Authors"]
#   authorlist <- strsplit(authors, split=", ")[[1]]
#   really_all_authors <- c(all_authors, authorlist)
# }
# 
# triplicate_authors <- data.frame(table(unlist(really_all_authors))) %>%
#   filter(Freq > 2)
# 
# quad_authors <- data.frame(table(unlist(really_all_authors))) %>%
#   filter(Freq > 3)
# 
# really_all_authors <- really_all_authors[really_all_authors != ":" | really_all_authors != "."]
```

```{r}
# # WARNING: This code takes a while to run
# authors.df <- data.frame(Source=character(),
#                          Target=character())
# 
# src.target <- function(x){
#   combos <- subset(expand.grid(rep(list(x),2)), Var1 != Var2)
#   return(combos)
# }
# 
# for(i in 1:nrow(articles_major_cats)){
#   authors <- articles_major_cats[i, "Authors"]
#   authorlist <- strsplit(authors, split=", ")[[1]]
#   if(length(authorlist) > 1 & any(authorlist %in% duplicate_authors)){
#     authors.df <- rbind(as.matrix(authors.df), as.matrix(src.target(authorlist)))
#   }
# }
# 
# authors.df <- data.frame(authors.df)
```


```{r}
# # need to remove rows that are like "a","b" vs "b", "a"
# subsetted.authors.src.target <- subset(authors.df, authors.df$Source %in% duplicate_authors)
# 
# # contains a column containing the number of interactiosn between two authors
# triplicate.authors.src.target <- subset(authors.df, authors.df$Source %in% triplicate_authors$Var1)
# triplicate.authors.src.target <- triplicate.authors.src.target %>%
#   group_by(Source, Target) %>%
#   summarize(count = n())
# # need to remove rows that are like "a","b" vs "b", "a"
# newDf <- data.frame(t(apply(triplicate.authors.src.target,1,sort)))
# newDf <- newDf[!duplicated(newDf),]
```

```{r}
# # contains a column containing the number of interactiosn between two authors
# quad.authors.src.target <- subset(authors.df, authors.df$Source %in% quad_authors$Var1)
# quad.authors.src.target <- quad.authors.src.target %>%
#   group_by(Source, Target) %>%
#   summarize(count = n())
# # need to remove rows that are like "a","b" vs "b", "a"
# newDf4 <- data.frame(t(apply(quad.authors.src.target,1,sort)))
# newDf4 <- newDf4[!duplicated(newDf4),]
```

Still having issues. I'm going to create a count of how many authors an author interacts with for bubble sizing
"A", 24
"B", 3

but only make a network graph with nodes of authors on more than one paper
so count all instances of an author
then filter the src.target for targets in duplicated list

```{r}
# author.counts <- data.frame(table(unlist(really_all_authors)))
# 
# heavilytrimmed3ormore <- newDf[which(newDf$X3 %in% triplicate_authors$Var1),]
```

Still only gets us down to 7831 nodes....

Let's visualize only authors on 2 papers
```{r}
# only_2_authors <- data.frame(table(unlist(really_all_authors))) %>%
#   filter(Freq == 2)
# 
# # contains a column containing the number of interactiosn between two authors
# only2.authors.src.target <- subset(authors.df, authors.df$Source %in% only_2_authors$Var1)
# only2.authors.src.target <- only2.authors.src.target %>%
#   group_by(Source, Target) %>%
#   summarize(count = n())
# # need to remove rows that are like "a","b" vs "b", "a"
# newDf.2 <- data.frame(t(apply(only2.authors.src.target,1,sort)))
# newDf.2 <- newDf.2[!duplicated(newDf.2),]
# newDf.2 <- newDf.2[which(newDf.2$X1 != ":"),]
# # yields 12899 unique authors
```

### Make the nodes papers? connect publications if at least 1 author shared between them.
```{r}
# # we'll use duplicated authors to check if a paper might have a shared paper
# # then create a list or the shared papers
# # then make the first paper source and the list all targets
# article.id.src.target.df <- data.frame(Source=character(),
#                          Target=character())
# 
# for(i in 1:nrow(articles_major_cats)){
#   authors <- articles_major_cats[i, "Authors"]
#   authorlist <- strsplit(authors, split=", ")[[1]]
#   authorlist <- authorlist[-which(authorlist %in% c(".", ":"))]
#   tmp.hold <- data.frame(Source=character(),
#                          Target=character())
#   for(author in authorlist){
#     authors.other.articles <- list(articles_major_cats[grep(author, articles_major_cats$Authors), "arxiv-id"])[[1]]
#     authors.other.articles <- authors.other.articles[which(authors.other.articles != articles_major_cats[i, "arxiv-id"])]
#     if(length(authors.other.articles) >0){
#       combos <- cbind(articles_major_cats[i,"arxiv-id"], authors.other.articles)
#       tmp.hold <- rbind(as.matrix(tmp.hold), as.matrix(combos))
#     }
#   article.id.src.target.df <- rbind(as.matrix(article.id.src.target.df), as.matrix(tmp.hold))
#   }
# }
# 
# # need to remove rows that are like "a","b" vs "b", "a"
# min.article.ids.src.target <- data.frame(t(apply(article.id.src.target.df,1,sort)))
# min.article.ids.src.target <- min.article.ids.src.target[!duplicated(min.article.ids.src.target),]
```
